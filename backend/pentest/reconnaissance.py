"""Reconnaissance and information gathering module"""

from typing import List, Dict, Any
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from .base import BasePentestModule
from ..models import Vulnerability, VulnerabilityType, SeverityLevel
import re


class ReconModule(BasePentestModule):
    """Information gathering and reconnaissance"""
    
    def get_module_name(self) -> str:
        return "Reconnaissance"
    
    async def scan(self, url: str, context: Dict[str, Any] = None) -> List[Vulnerability]:
        """Perform reconnaissance on the target"""
        self.vulnerabilities = []
        
        # Check robots.txt
        await self.check_robots_txt(url)
        
        # Detect technologies
        await self.detect_technologies(url)
        
        # Find sensitive files
        await self.find_sensitive_files(url)
        
        # Enumerate directories
        await self.basic_directory_enum(url)
        
        # Check security headers
        await self.check_security_headers(url)
        
        return self.vulnerabilities
    
    async def check_robots_txt(self, base_url: str):
        """Check robots.txt for sensitive information"""
        robots_url = urljoin(base_url, "/robots.txt")
        response = await self.make_request(robots_url)
        
        if response and response.status_code == 200:
            content = response.text
            disallowed_paths = []
            
            for line in content.split('\n'):
                if line.startswith('Disallow:'):
                    path = line.split(':', 1)[1].strip()
                    if path and path != '/':
                        disallowed_paths.append(path)
            
            if disallowed_paths:
                self.create_vulnerability(
                    vuln_type=VulnerabilityType.SECURITY_MISCONFIG,
                    severity=SeverityLevel.INFO,
                    title="Information Disclosure in robots.txt",
                    description="The robots.txt file reveals potentially sensitive paths",
                    affected_url=robots_url,
                    evidence=f"Found {len(disallowed_paths)} disallowed paths: {', '.join(disallowed_paths[:5])}",
                    reproduction_steps=[
                        f"1. Navigate to {robots_url}",
                        "2. Review the Disallow directives",
                        "3. Investigate the listed paths for sensitive information"
                    ],
                    remediation="Ensure robots.txt doesn't reveal sensitive directory structure. Only include necessary paths.",
                    cwe_id="CWE-200"
                )
    
    async def detect_technologies(self, url: str):
        """Detect technologies used by the target"""
        response = await self.make_request(url)
        
        if not response:
            return
        
        technologies = []
        
        # Check headers for technology indicators
        server = response.headers.get('Server', '')
        if server:
            technologies.append(f"Server: {server}")
        
        x_powered_by = response.headers.get('X-Powered-By', '')
        if x_powered_by:
            technologies.append(f"X-Powered-By: {x_powered_by}")
        
        # Check HTML for technology indicators
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Check for frameworks
        if soup.find(attrs={"data-react-root": True}) or soup.find(id=re.compile(r'react-')):
            technologies.append("Frontend: React")
        
        if soup.find(attrs={"ng-version": True}):
            technologies.append("Frontend: Angular")
        
        # Check for meta tags
        for meta in soup.find_all('meta'):
            if meta.get('name') == 'generator':
                technologies.append(f"Generator: {meta.get('content')}")
        
        if technologies:
            self.create_vulnerability(
                vuln_type=VulnerabilityType.SECURITY_MISCONFIG,
                severity=SeverityLevel.INFO,
                title="Technology Stack Detection",
                description="Detected technologies in use",
                affected_url=url,
                evidence="\n".join(technologies),
                reproduction_steps=[
                    f"1. Visit {url}",
                    "2. Inspect HTTP headers and HTML source",
                    "3. Identify technology indicators"
                ],
                remediation="Consider removing or obfuscating technology version information in headers and HTML.",
                cwe_id="CWE-200"
            )
    
    async def find_sensitive_files(self, base_url: str):
        """Check for common sensitive files"""
        sensitive_files = [
            ".env",
            ".git/config",
            "config.php",
            "wp-config.php",
            ".htaccess",
            "phpinfo.php",
            "info.php",
            "backup.sql",
            "database.sql",
            ".env.backup",
            "composer.json",
            "package.json"
        ]
        
        found_files = []
        
        for filename in sensitive_files:
            url = urljoin(base_url, filename)
            await self.rate_limit()
            response = await self.make_request(url)
            
            if response and response.status_code == 200:
                found_files.append(filename)
        
        if found_files:
            self.create_vulnerability(
                vuln_type=VulnerabilityType.SENSITIVE_DATA,
                severity=SeverityLevel.HIGH,
                title="Exposed Sensitive Files",
                description="Sensitive configuration or backup files are publicly accessible",
                affected_url=base_url,
                evidence=f"Found accessible files: {', '.join(found_files)}",
                reproduction_steps=[
                    f"1. Access {urljoin(base_url, found_files[0])}",
                    "2. Verify the file is accessible without authentication"
                ],
                remediation="Remove or protect sensitive files. Ensure .env, config files, and backups are not web-accessible.",
                cwe_id="CWE-538",
                cvss_score=7.5
            )
    
    async def basic_directory_enum(self, base_url: str):
        """Enumerate common directories"""
        common_dirs = [
            "admin",
            "administrator",
            "wp-admin",
            "phpmyadmin",
            "backup",
            "test",
            "dev",
            "api",
            "uploads",
            "files"
        ]
        
        found_dirs = []
        
        for directory in common_dirs:
            url = urljoin(base_url, directory + "/")
            await self.rate_limit()
            response = await self.make_request(url, follow_redirects=False)
            
            if response and response.status_code in [200, 301, 302, 403]:
                found_dirs.append((directory, response.status_code))
        
        if found_dirs:
            accessible = [d for d, code in found_dirs if code == 200]
            forbidden = [d for d, code in found_dirs if code == 403]
            
            if accessible:
                self.create_vulnerability(
                    vuln_type=VulnerabilityType.SECURITY_MISCONFIG,
                    severity=SeverityLevel.MEDIUM,
                    title="Accessible Administrative Directories",
                    description="Potentially sensitive directories are accessible",
                    affected_url=base_url,
                    evidence=f"Accessible directories: {', '.join(accessible)}",
                    reproduction_steps=[
                        f"1. Navigate to {urljoin(base_url, accessible[0] + '/')}",
                        "2. Observe the directory is accessible"
                    ],
                    remediation="Implement proper access controls on administrative and sensitive directories.",
                    cwe_id="CWE-552"
                )
    
    async def check_security_headers(self, url: str):
        """Check for missing security headers"""
        response = await self.make_request(url)
        
        if not response:
            return
        
        required_headers = {
            "Strict-Transport-Security": "HSTS",
            "X-Content-Type-Options": "Content Type Options",
            "X-Frame-Options": "Clickjacking Protection",
            "Content-Security-Policy": "CSP",
            "X-XSS-Protection": "XSS Protection",
            "Referrer-Policy": "Referrer Policy"
        }
        
        missing_headers = []
        
        for header, description in required_headers.items():
            if header not in response.headers:
                missing_headers.append(f"{header} ({description})")
        
        if missing_headers:
            self.create_vulnerability(
                vuln_type=VulnerabilityType.SECURITY_MISCONFIG,
                severity=SeverityLevel.MEDIUM,
                title="Missing Security Headers",
                description="Important security headers are not configured",
                affected_url=url,
                evidence=f"Missing headers: {', '.join(missing_headers)}",
                reproduction_steps=[
                    f"1. Send a request to {url}",
                    "2. Inspect the response headers",
                    "3. Note the absence of security headers"
                ],
                remediation="Configure the following security headers: " + ", ".join(missing_headers),
                cwe_id="CWE-693"
            )

